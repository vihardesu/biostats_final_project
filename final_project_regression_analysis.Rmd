---
title: "P8130 Final Project"
date: "12/17/2020"
output: 
  html_document: 
     toc: true
---

## Setup

##### Chunk Options
```{r setup, message = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  include = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 12,
  fig.asp = .6,
  fig.align = "center",
  out.width = "90%"
)
```

##### Installations
```{r}
library(tidyverse)
library(dplyr)
library(arsenal)
library(HH)
library(leaps)
library(corrplot)
library(faraway)
library(ggpubr)
library(broom)
library(ggplot2)
library(MASS)
library(patchwork)
library(caret)
```

##### Load Data Set
```{r}
hate_crime = read_csv("data/HateCrimes.csv", col_types = "fffdddddd") %>%
  janitor::clean_names() %>%
  drop_na()
```

---

## Data Exploration 

## Descriptive Summary of Data
```{r, echo=FALSE, results="asis"}
table_labels = list(
  hate_crimes_per_100k_splc = "Hate crime rate per 100,000 population",
  unemployment = "Level of unemployment",
  urbanization = "Level of state urbanization",
  median_household_income = "Median Household Income",
  perc_population_with_high_school_degree = "Percent of adults with a high school degree",
  perc_non_citizen = "Percent of population that are not US citizens",
  perc_non_white = "Percent of population that are non-white",
  gini_index = "Income inequality index"
)

# Table 1 Settings
summ_table_controls = tableby.control(
  total = F,
  test = F,
  numeric.stats = c("meansd", "medianq1q3", "range", "Nmiss"),
  cat.stats = c("countpct", "Nmiss"),
  stats.labels = list(
    meansd = "Mean (SD)",
    medianq1q3 = "Median (Q1, Q3)",
    range = "Min - Max",
    countpct = "N (%)"
  ),
  Nmiss = "Missing Value"
)

# Data Table generation
# Column separated by group with rows listing demographics and comorbidities

table_1 = tableby(
  ~ unemployment + urbanization + median_household_income + perc_population_with_high_school_degree + perc_non_citizen + gini_index + perc_non_white + hate_crimes_per_100k_splc,
  data = hate_crime,
  control = summ_table_controls,
  test = FALSE
)

#Generate Table 1
tab_summary = summary(
  table_1,
  title = "Descriptive Statistics: Hate Crime Rate After 2016 Election",
  labelTranslations = table_labels,
  text = T,
  digits = 2
)

tab_summary

#Code to save output in .csv format
#write.csv(tab_summary, './table1.csv')
```

## Outcome Distribution

##### Histogram of Outcome Variable

From the histogram below, we observe our outcome distribution has right skewness, suggesting that we may need to check our normality assumption. Our QQ Plot also indicates severe departures from normality.

```{r}
#Histogram of Outcome Distribution
hate_crime %>% 
  ggplot(aes(x = hate_crimes_per_100k_splc)) + 
  geom_histogram(color = "red", fill = "black") + 
  labs(
    title = "Distribution of Hate Crime Rates in 50 US States",
    x = "Hate Crime Rate per 100,000 Population",
    y = "Frequency of Distribution",
    caption = "Distribution of Hate Crime Rates ( 50 US States)")
```

##### QQ Plot of Outcome Variable

```{r}
#QQplot of Outcome Distribution
hate_crimes_per_100k_splc = hate_crime$hate_crimes_per_100k_splc
qqnorm(hate_crimes_per_100k_splc, col = 2, pch = 19, cex = 1.5)
qq_plot = qqline(hate_crimes_per_100k_splc, col = 1,lwd = 2,lty = 2)
```

##### Shapiro-Wilk Test of Outcome Variable

After performing a Shapiro-Wilk test to check the normality assumption of our outcome distribution, we find evidence to suggest that our data deviates from normality.

```{r}
# Perform Shapiro-Wilk test
shapiro.test(hate_crimes_per_100k_splc) %>% 
  broom::tidy() %>% 
  knitr::kable("simple")
```

##### Comparison of Basic Transformations

We apply a square root transformation and a natural log transformation to our outcome distribution, and compare the results of the data.

```{r}
sqrt_transformation = hate_crime %>% 
  ggplot(aes(x = sqrt(hate_crimes_per_100k_splc))) + 
  geom_histogram(color = "red", fill = "black") + 
  labs(
    title = "Distribution of sqrt(Hate Crime Rates) in 50 US States",
    x = "sqrt(Hate Crime Rate per 100,000 Population)",
    y = "Frequency of Distribution",
    caption = "Distribution of Hate Crime Rates ( 50 US States)")

sqrt_qqplot = ggplot(hate_crime, aes(sample = sqrt(hate_crimes_per_100k_splc))) +
  stat_qq() + stat_qq_line() + 
  labs(
    title = "QQ Plot of sqrt(Hate Crime Rates) in 50 US States",
    x = "sqrt(Hate Crime Rate per 100,000 Population)",
    y = "Frequency of Distribution",
    caption = "Distribution of Hate Crime Rates ( 50 US States)")

ln_transformation = hate_crime %>% 
  ggplot(aes(x = log(hate_crimes_per_100k_splc))) + 
  geom_histogram(color = "red", fill = "black") + 
  labs(
    title = "Distribution of ln(Hate Crime Rates) in 50 US States",
    x = "ln(Hate Crime Rate per 100,000 Population)",
    y = "Frequency of Distribution",
    caption = "Distribution of Hate Crime Rates ( 50 US States)")

ln_qqplot = ggplot(hate_crime, aes(sample = log(hate_crimes_per_100k_splc))) + stat_qq() + stat_qq_line() + 
  labs(
    title = "QQ Plot of ln(Hate Crime Rates) in 50 US States",
    x = "ln(Hate Crime Rate per 100,000 Population)",
    y = "Frequency of Distribution",
    caption = "Distribution of Hate Crime Rates ( 50 US States)")
```

##### Sqrt vs. Ln Transformations

After visual inspection, we observe that our natural log transformation may be a good candidate to re-test our normality assumptions.

```{r}
(sqrt_transformation + ln_transformation) / ( sqrt_qqplot + ln_qqplot)
```

##### Shapiro-Wilk Test on our Natural Log Transformation

From the results of our test, we observe that we fail to reject the null (our p-value > 0.05) and can state with 95% confidence that our natural log transformation does not significantly deviate from normality, so we can assume normality henceforth.

```{r}
shapiro.test(log(hate_crimes_per_100k_splc)) %>% 
  broom::tidy() %>% 
  knitr::kable("simple", caption = "Shapiro Wilk Test")
```

##### Box Cox Analysis

Box-Cox transformation was utilized to find out the recommended transformation. The optimal value of lambda is near 0, indicating that a natural logarithm transformation of the outcome is best for further analysis.

```{r}
removed_states = hate_crime %>% 
  dplyr::select(-state)

fit = lm(hate_crimes_per_100k_splc ~ ., data = removed_states)
fit %>% MASS::boxcox()
```

##### Adding Linear Transformation
```{r}
hate_crime = hate_crime %>% 
  mutate(
    ln_hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)
)
```

## Identifying Outliers

```{r}
hate_crime %>%
  ggplot(aes(x = hate_crimes_per_100k_splc, y = state, colors = state)) + 
  geom_col(color = "blue") +
  labs(
    title = "Outlier Analysis of 50 US States",
    x = "Hate Crime Rate per 100,000 Population",
    y = "Frequency of Distribution",
    caption = "Distribution of Hate Crime Rates (50 US States)"
  ) 
```

Upon Plotting a column graph of the hate crimes against their respective states, we can see that Wyoming, South Dakota, and North Dakota had no values and District of Columbia, Washington, Oregon, Minnesota, Massachusetts and Maine showed relatively large columns.

After Plotting a scatter plot of the same values, it was evident that these states were outliers that influenced the data set.

```{r}
hate_crime %>%
  ggplot(aes(y = hate_crimes_per_100k_splc, x = state, colors = state)) +
  geom_point(aes(color = state)) +
  geom_smooth(method = "lm", se = F, color = "red") +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "none") +
  labs(
    title = "Outlier Analysis of 50 US States",
    x = "State",
    y = "Hate Crime Rate per 100,000 Population",
    caption = "Distribution of Hate Crime Rates (50 US States)"
  ) 
```

##### Check for Influential Points
```{r}
# check for influential points
multi.fit1 = lm(hate_crimes_per_100k_splc ~., data = removed_states)
influence.measures(multi.fit1)
stu_res<-rstandard(multi.fit1)
outliers_y<-stu_res[abs(stu_res)>2.5]
outliers_y
par(mfrow = c(2, 2))
plot(multi.fit1)
```

## Associations b/w Predictors and Hate Crime Rate

We verify if the association between income inequality (median household income in this case), holds true, as well as explore associations of all the other covariates mentioned above and draw your own conclusions about each predictor's significance.  

##### Correlation Matrix of Predictors and Outcome
```{r, fig.width = 12, fig.height = 12}
hate_crime %>% 
  dplyr::select(-state,-unemployment,-urbanization) %>% 
  cor() %>% 
  knitr::kable(digits = 2)

hate_crime %>% 
  dplyr::select(-state,-unemployment,-urbanization) %>%  #removing factor variables
  cor() %>% 
  corrplot::corrplot(method = "circle", type = "upper", diag = FALSE)
```

##### Correlation Plots between Predictors and Outcome

```{r}
a = ggscatter(hate_crime, x = "median_household_income", y = "hate_crimes_per_100k_splc", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Median Household Income", ylab = "Hate Crime Rate (per 100k pop.)")

b = ggscatter(hate_crime, x = "perc_population_with_high_school_degree", y = "hate_crimes_per_100k_splc", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "% of People 25+ with High School Degree", ylab = "Hate Crime Rate (per 100k pop.)")

c = ggscatter(hate_crime, x = "perc_non_citizen", y = "hate_crimes_per_100k_splc", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "% of People Non-US Citizens", ylab = "Hate Crime Rate (per 100k pop.)")

d = ggscatter(hate_crime, x = "gini_index", y = "hate_crimes_per_100k_splc", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Income Inequality Index (0-100)", ylab = "Hate Crime Rate (per 100k pop.)")

e = ggscatter(hate_crime, x = "perc_non_white", y = "hate_crimes_per_100k_splc", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "% of People Non-White", ylab = "Hate Crime Rate (per 100k pop.)")
```

From our results, we observe that predictors, "gini_index" and "median_household_income" have the highest correlations to our outcome of interest.

```{r}
(a + b + c) / (d + e)
```

## Multicollinearity

```{r}
# Scatter plot showing associations between numeric variables
hate_crime %>%
  dplyr::select(-state,-unemployment,-urbanization) %>%
  pairs()
```

##### Calculating VIF for all the predictors

```{r}
# fitting MLR model on tidy data without state variable
mult_fit <-
  lm(
    ln_hate_crimes_per_100k_splc ~ unemployment + urbanization + median_household_income + perc_population_with_high_school_degree + perc_non_citizen + gini_index + perc_non_white,
    data = hate_crime
  )

vif(mult_fit) %>% knitr::kable("simple")
```

All the predictors have a VIF below 5. This suggests that it would not be problematic to include them in the construction of the model. However, the correlation analysis shows that variables `perc_non_white` and `perc_non_citizen` have a moderate linear relationship with a correlation coefficient of 0.75.

## Analysis of Predictor Interactions

```{r, include=FALSE}
#Low=0,High=1
hate_crime1 = hate_crime
hate_crime1$unemployment = factor(hate_crime1$unemployment, levels = c("low", "high"))
hate_crime1$unemployment = as.numeric(hate_crime1$unemployment) - 1
hate_crime1$urbanization = factor(hate_crime1$urbanization, levels = c("low", "high"))
hate_crime1$urbanization = as.numeric(hate_crime1$urbanization) - 1
hate_crime1$hate_crimes_per_100k_splc = as.numeric(hate_crime1$hate_crimes_per_100k_splc)
hate_crimedf = dplyr::select(hate_crime1, -1)
is.na.data.frame(hate_crimedf)
hate_crimedf = na.omit(hate_crimedf)
hate_crimedft = dplyr::select(hate_crime1, -1)
hate_crimedft = na.omit(hate_crimedft)
hate_crimedft$hate_crimes_per_100k_splc = log2(hate_crimedft$hate_crimes_per_100k_splc)
hate_crimedft$gini_index = log2(hate_crimedft$gini_index)
hate_crimedft$perc_population_with_high_school_degree = log2(hate_crimedft$perc_population_with_high_school_degree)
```


##### Interaction between income equality and unemployment 

```{r}
ggplot(hate_crimedft,
       aes(
         x = gini_index,
         y = ln_hate_crimes_per_100k_splc,
         colour = factor(unemployment)
       )) +
  geom_point(size = 2) +
  geom_smooth(method = "lm",
              se = F,
              aes(
                group = factor(unemployment),
                color = factor(unemployment)
              )) +
  labs(title = "Scatterplot of ln(hate crime per 100k people) vs ln(income equality) by Unemployment Status",
       x = "ln(gini index)", y = "ln(hate crime per 100k people)") +
  scale_color_manual(
    name = "Unemployment",
    labels = c("Low", "High"),
    values = c("blue", "red")
  )
reg1t <-
  lm(ln_hate_crimes_per_100k_splc ~ gini_index * factor(unemployment),
     data = hate_crimedft)
summary(reg1t)
```

There is no significant interaction at 5% significance level. The relationship between hate crime per 100k people and income equality does not vary by unemployment status.

##### Interaction between income equality and urbanization 

```{r}
#Scatter plot - Hate_crime_per_100k_splc vs. gini index by urbanization 
ggplot(hate_crimedft, aes(x =gini_index, y = ln_hate_crimes_per_100k_splc, colour = factor(urbanization))) +         
  geom_point(size = 2) +                                                                     
  geom_smooth(method = "lm", se = F,                                          
              aes(group = factor(urbanization),                                  
                  color = factor(urbanization))) +                                        
  labs(title = "Scatterplot of ln(hate crime per 100k people) vs ln(income equality) by Urbanization Status", 
       x = "ln(gini index)", y = "ln(hate crime per 100k people)") +
  scale_color_manual(name = "Urbanization", labels = c("Low", "High"), values = c("blue", "red"))    
reg2t <- lm(ln_hate_crimes_per_100k_splc ~ gini_index*factor(urbanization), data = hate_crimedft)
summary(reg2t)
```
There is no significant interaction at 5% significance level.The relationship between hate crime per 100k people and income equality does not vary by urbanization status.

##### Interaction between education level and unemployment 
```{r}
ggplot(
  hate_crimedft,
  aes(
    x = perc_population_with_high_school_degree,
    y = ln_hate_crimes_per_100k_splc,
    colour = factor(unemployment)
  )
) +
  geom_point(size = 2) +
  geom_smooth(method = "lm",
              se = F,
              aes(
                group = factor(unemployment),
                color = factor(unemployment)
              )) +
  labs(title = "Scatterplot of ln(hate crime per 100k people) vs ln(education level) by Unemployment status",
       x = "ln(percentage of population with high school degree and higher)", y = "ln(hate crime per 100k people)") +
  scale_color_manual(
    name = "Unemployment",
    labels = c("Low", "High"),
    values = c("blue", "red")
  )
reg11t <-
  lm(
    ln_hate_crimes_per_100k_splc ~ perc_population_with_high_school_degree * factor(unemployment),
    data = hate_crimedft
  )
summary(reg11t)
```

There is no significant interaction at 5% significance level. The relationship between hate crime per 100k people and education level does not vary by unemployment status.

##### Interaction between education level and urbanization 

```{r}
#Scatter plot - Hate_crime_per_100k_splc vs. education level by urbanization 
ggplot(hate_crimedft, aes(x = perc_population_with_high_school_degree, y = ln_hate_crimes_per_100k_splc, colour = factor(urbanization))) +         
  geom_point(size = 2) +                                                                     
  geom_smooth(method = "lm", se = F,                                          
              aes(group = factor(urbanization),                                  
                  color = factor(urbanization))) +                                        
  labs(title = "Scatterplot of ln(hate crime per 100k people) vs ln(education level) by Urbanization status", 
       x = "ln(percentage of population with high school degree or higher)", y = "ln(hate crime per 100k people)") +
  scale_color_manual(name = "Urbanization", labels = c("Low", "High"), values = c("blue", "red"))    
reg22t <- lm(ln_hate_crimes_per_100k_splc ~ perc_population_with_high_school_degree*factor(urbanization), data = hate_crimedft)
summary(reg22t)
```

There is no significant interaction at 5% significance level.The relationship between hate crime per 100k people and education level does not vary by urbanization status.

## Model Selection

Fit model with all predictors
```{r}
hate_crime_no_dc <- hate_crime[c(-9),] %>%
  dplyr::select(-state)

mult.fit <- lm(log(hate_crimes_per_100k_splc) ~ ., data = hate_crime_no_dc)
step(mult.fit, direction='both')
```

Based on the results of stepwise procedure, we choose model with 2 predictors: percent of adults 25 and older with a high school degreee and gini index.  
  
##### Fit MLR based on Stepwise Model Result

```{r}
stepwise_log_fit = lm(
  log(hate_crimes_per_100k_splc) ~ perc_population_with_high_school_degree + gini_index,
  data = hate_crime_no_dc
)
```

## Model Diagnostics

```{r}
#Check model assumptions:
par(mfrow = c(2, 2))
plot(stepwise_log_fit)
```

##### Model Validation
```{r}
set.seed(1)

data_train <- trainControl(method = "cv", number = 5)

model_caret <-
  train(
    log(hate_crimes_per_100k_splc) ~ perc_population_with_high_school_degree + gini_index,
    data = hate_crime_no_dc,
    trControl = data_train,
    method = 'lm',
    na.action = na.pass
  )

model_caret
```



