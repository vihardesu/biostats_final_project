---
title: "P8130 Final Project"
date: "12/17/2020"
output: 
  html_document: 
     toc: true
---

```{r setup, message = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  include = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  fig.align = "center",
  out.width = "90%"
)

library(tidyverse)
library(dplyr)
library(arsenal)
library(HH)
library(leaps)
library(corrplot) 
library(faraway)
library(broom)
library(ggplot2)
library(MASS)
```

Load Data Set
```{r}
hate_crime = read_csv("data/HateCrimes.csv", col_types = "fffdddddd") %>% 
  janitor::clean_names()
```

---

# Data Exploration: 

## Descriptive statistics: Table 1


```{r, echo=FALSE, results="asis"}
table_labels = list(
   hate_crimes_per_100k_splc = "Hate crime rate per 100,000 population",
   unemployment = "Level of unemployment",
   urbanization = "Level of state urbanization",
   median_household_income = "Median Household Income",
   perc_population_with_high_school_degree = "Percent of adults with a high school degree",
   perc_non_citizen = "Percent of population that are not US citizens",
   perc_non_white = "Percent of population that are non-white",
   gini_index = "Income inequality index")

# Table 1 settings
summ_table_controls = tableby.control(
  total = F,
  test = F,
  numeric.stats = c("meansd", "medianq1q3", "range", "Nmiss"),
  cat.stats = c("countpct", "Nmiss"),
  stats.labels = list(
    meansd = "Mean (SD)",
    medianq1q3 = "Median (Q1, Q3)",
    range = "Min - Max",
    countpct = "N (%)"),
    Nmiss = "Missing Value"
  )

# Data Table generation; column separated by Group with rows listing demographics and comorbidities

table_1 = tableby( ~ unemployment + urbanization + median_household_income + perc_population_with_high_school_degree + perc_non_citizen + gini_index + perc_non_white + hate_crimes_per_100k_splc, 
                   data = hate_crime, 
                   control = summ_table_controls,
                   test = FALSE)

# table1 generate
summary(table_1, 
        title = "Descriptive Statistics: Hate Crime Rate After 2016 Election",
        labelTranslations = table_labels,
        text = T,
        digits = 2) 
```


## Visualization 

##### Histogram of Outcome Variable

From the histogram below, we observe our outcome distribution has right skewness, suggesting that we may need to check our normality assumption. Our QQ Plot also indicates severe departures from normality.

```{r}
#Histogram of Outcome Distribution
hate_crime %>% 
  ggplot(aes(x = hate_crimes_per_100k_splc)) + 
  geom_histogram(color = "red", fill = "black") + 
  labs(
    title = "Distribution of Hate Crime Rates in 50 US States",
    x = "Hate Crime Rate per 100,000 Population",
    y = "Frequency of Distribution",
    caption = "Distribution of Hate Crime Rates ( 50 US States)")
```

##### QQ Plot of Outcome Variable
```{r}
#QQplot of Outcome Distribution
hate_crimes_per_100k_splc = hate_crime$hate_crimes_per_100k_splc
qqnorm(hate_crimes_per_100k_splc, col = 2, pch = 19, cex = 1.5)
qq_plot = qqline(hate_crimes_per_100k_splc, col = 1,lwd = 2,lty = 2)
```

##### Shapiro-Wilk Test of Outcome Variable

After performing a Shapiro-Wilk test to check the normality assumption of our outcome distribution, we find evidence to suggest that our data deviates from normality.

```{r}
# Perform Shapiro-Wilk test
shapiro.test(hate_crimes_per_100k_splc) %>% 
  broom::tidy() %>% 
  knitr::kable("simple")
```

##### Outcome Translation to fit Normality (Vihar)

Identify states with unusual rates and consider them as potential outliers/influential points. (Jyoti) 



# Income inequality was the main predictor of hate crime rates


#### Verify if this association holds true, as well as explore associations of all the other covariates mentioned above and draw your own conclusions.(Linh)\

```{r, fig.width = 12, fig.height = 12}
hate_crime %>% 
  drop_na() %>% 
  dplyr::select(-state,-unemployment,-urbanization) %>% 
  cor() %>% 
  knitr::kable(digits = 2)

hate_crime %>% 
  drop_na() %>% 
  dplyr::select(-state,-unemployment,-urbanization) %>%  #removing factor variables
  cor() %>% 
  corrplot::corrplot(method = "circle", type = "upper", diag = FALSE)
```


#### Multicollinearity (Nikhita)\

```{r}
# Scatter plot showing associations between numeric variables

hate_crime %>%
  dplyr::select(-state,-unemployment,-urbanization) %>%
  pairs()
  

```

Calcu
```{r}

```

Yanzhe Ma (TBC, before transformation)
```{r, include=FALSE}
#Low=0,High=1
hate_crime1 = hate_crime
hate_crime1$unemployment = factor(hate_crime1$unemployment,levels = c("low","high"))
hate_crime1$unemployment = as.numeric(hate_crime1$unemployment) - 1
hate_crime1$urbanization = factor(hate_crime1$urbanization,levels = c("low","high"))
hate_crime1$urbanization = as.numeric(hate_crime1$urbanization) - 1
hate_crime1$hate_crimes_per_100k_splc = as.numeric(hate_crime1$hate_crimes_per_100k_splc)
hate_crimedf = dplyr::select(hate_crime1,-1)
#Check the N/A values and omit
is.na.data.frame(hate_crimedf)
hate_crimedf = na.omit(hate_crimedf)
```

##### Interaction between income equality and unemployment 
```{r}
#Scatter plot - Hate_crime_per_100k_splc vs. gini index by unemploymnet 
ggplot(hate_crimedf, aes(x = gini_index, y = hate_crimes_per_100k_splc, colour = factor(unemployment))) +         
  geom_point(size = 2) +                                                                     
  geom_smooth(method = "lm", se = F,                                          
              aes(group = factor(unemployment),                                  
                  color = factor(unemployment))) +                                        
  labs(title = "Scatterplot of Hate crime per 100k people vs. income equality by unemploymnet status", 
       x = "gini index", y = "hate crime per 100k people") +
  scale_color_manual(name = "Unemployment", labels = c("Low", "High"), values = c("blue", "red"))    
reg1 <- lm(hate_crimes_per_100k_splc ~ gini_index*factor(unemployment), data = hate_crimedf)
summary(reg1)
```

There is no significant interaction at 5% significance level. The relationship between hate crime per 100k people and income equality does not vary bt unemployment status.
Hence, stratified analysis is not included.

```{r, echo=FALSE, include=FALSE}
#low employment 
lowempdf <- filter(hate_crimedf, unemployment == "0") 
lowempreg <- lm(hate_crimes_per_100k_splc ~ gini_index, data = lowempdf)
summary(lowempreg)
# high employment 
highempdf <- filter(hate_crimedf, unemployment == "1") 
highempreg <- lm(hate_crimes_per_100k_splc ~ gini_index, data = highempdf)
summary(highempreg)
```

##### Interaction between income equality and urbanization 
```{r}
#Scatter plot - Hate_crime_per_100k_splc vs. gini index by urbanization 
ggplot(hate_crimedf, aes(x = gini_index, y = hate_crimes_per_100k_splc, colour = factor(urbanization))) +         
  geom_point(size = 2) +                                                                     
  geom_smooth(method = "lm", se = F,                                          
              aes(group = factor(urbanization),                                  
                  color = factor(urbanization))) +                                        
  labs(title = "Scatterplot of Hate crime per 100k people vs. income equality by urbanization status", 
       x = "gini index", y = "hate crime per 100k people") +
  scale_color_manual(name = "Urbanization", labels = c("Low", "High"), values = c("blue", "red"))    
reg2 <- lm(hate_crimes_per_100k_splc ~ gini_index*factor(urbanization), data = hate_crimedf)
summary(reg2)
```

There is no significant interaction at 5% significance level.The relationship between hate crime per 100k people and income equality does not vary by urbanization status.
Hence, stratified analysis is not included.

```{r, echo=FALSE, include=FALSE}
#Stratified analysis
#low urbanization
lowurdf <- filter(hate_crimedf, urbanization == "0") 
lowurreg <- lm(hate_crimes_per_100k_splc ~ gini_index, data = lowurdf)
summary(lowurreg)
#high urbanization 
highurdf <- filter(hate_crimedf, urbanization == "1") 
highurreg <- lm(hate_crimes_per_100k_splc ~ gini_index, data = highurdf)
summary(highurreg)
```

# Model diagnostics 

Check model assumptions and goodness of fit (Vihar Desu)

```{r}
hate_crime = 
  hate_crime %>% 
  drop_na() %>% 
  dplyr::select(-state)

hate_crime_fit = lm(hate_crimes_per_100k_splc ~., data = hate_crime)
summary(hate_crime_fit)
```

Box-Cox without transformation

```{r}
hate_crime_fit %>% 
  MASS::boxcox()
```

Take log transformation

```{r}
hate_crime_log_fit = lm(log(hate_crimes_per_100k_splc) ~ . ,
                    data = hate_crime)
```

## QQ plot for model with transformation and without transformation


```{r}
par(mfrow = c(1, 2))

# without transformation
qqnorm(resid(hate_crime_fit), xlab = "Expected Value", ylab = "Residual", main = "")
qqline(resid(hate_crime_fit))
title("QQ Plot for Hate crime rate")

# with transformation
qqnorm(resid(hate_crime_log_fit), xlab = "Expected Value", ylab = "Residual", main = "")
qqline(resid(hate_crime_log_fit))
title("QQ Plot for Ln(Hate crime rate)")
```

Log transformation is better.

# Model Selection

Stepwise selection

```{r}
step(hate_crime_fit, direction = "backward")

#lm(hate_crimes_per_100k_splc ~ perc_population_with_high_school_degree + gini_index, data = hate_crime)
```
